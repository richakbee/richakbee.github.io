<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>jupyter | Richa Kaur</title>
    <link>https://richakbee.github.io/tag/jupyter/</link>
      <atom:link href="https://richakbee.github.io/tag/jupyter/index.xml" rel="self" type="application/rss+xml" />
    <description>jupyter</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>©.2021</copyright><lastBuildDate>Sun, 08 Nov 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://richakbee.github.io/images/icon_hu6bff33d6d21873592e5202e35658285b_19800_512x512_fill_lanczos_center_2.png</url>
      <title>jupyter</title>
      <link>https://richakbee.github.io/tag/jupyter/</link>
    </image>
    
    <item>
      <title>Convolution Neural Network from Scratch</title>
      <link>https://richakbee.github.io/post/cnn_from_scratch/</link>
      <pubDate>Sun, 08 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://richakbee.github.io/post/cnn_from_scratch/</guid>
      <description>&lt;h2 id=&#34;import-libraries--data&#34;&gt;Import Libraries &amp;amp; Data&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import matplotlib.pyplot as plt
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import skimage.data  
# Reading the image  
img = skimage.data.chelsea()  
# Converting the image into gray.  
#img = skimage.color.rgb2gray(img)
print(img.shape)
plt.imshow(img)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(300, 451, 3)





&amp;lt;matplotlib.image.AxesImage at 0x1f452f43088&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/output_3_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/Architecture.jpg&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;funcions&#34;&gt;Funcions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;zero padding&lt;/li&gt;
&lt;li&gt;colvolution operation&lt;/li&gt;
&lt;li&gt;forward pass in convolution&lt;/li&gt;
&lt;li&gt;pooling operation forward&lt;/li&gt;
&lt;li&gt;backward pass in colvolution&lt;/li&gt;
&lt;li&gt;pooling operation backward&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;zero-padding&#34;&gt;Zero padding&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/zeropadding.jpg&#34; alt=&#34;image.jpg&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def zero_pad(X, pad):
    &amp;quot;&amp;quot;&amp;quot;
    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, 
    as illustrated in Figure 1.
    
    Argument:
    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images
    pad -- integer, amount of padding around each image on vertical and horizontal dimensions
    
    Returns:
    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)
    &amp;quot;&amp;quot;&amp;quot;
    X_pad= np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),mode=&amp;quot;constant&amp;quot;,constant_values=(0,0))
    
    return X_pad
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x=np.expand_dims(img, axis=0)
x_pad=zero_pad(x,20)
print(x.shape,x_pad.shape)
fig,axs=plt.subplots(1,2)

axs[0].imshow(x[0,:,:,:])
axs[0].set_title(&#39;X&#39;)
axs[1].imshow(x_pad[0,:,:,:])
axs[1].set_title(&#39;X_pad&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(1, 300, 451, 3) (1, 340, 491, 3)





Text(0.5, 1.0, &#39;X_pad&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/output_8_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;convolution-operation&#34;&gt;Convolution operation&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/convolutionstep.gif&#34; alt=&#34;image.gif&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def conv_single_step(a_slice_prev, W, b):
    &amp;quot;&amp;quot;&amp;quot;
    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation 
    of the previous layer.
    
    Arguments:
    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)
    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)
    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)
    
    Returns:
    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data
    &amp;quot;&amp;quot;&amp;quot;
    s=np.multiply(a_slice_prev,W)
    
    Z=np.sum(s)
    
    Z=Z+np.float(b)
    
    return Z
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;l1_filter=np.zeros((3,3,3))
l1_filter[:, :,0] = np.array([[[-1, 0, 1],   
                                    [-1, 0, 1],   
                                     [-1, 0, 1]]])  
l1_filter[:, :, 1] = np.array([[[1,   1,  1],   
                                     [0,   0,  0],   
                                    [-1, -1, -1]]]) 
l1_filter[:, :, 2] = np.array([[[1,   1,  1],   
                                     [0,   0,  0],   
                                    [-1, -1, -1]]]) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#for a slice
np.random.seed(1)
a_slice_prev = img[20:23,20:23,:]
plt.imshow(img[20:23,20:23,:])
W = l1_filter
b = np.random.randn(1, 1, 1)

Z = conv_single_step(a_slice_prev, W, b)
print(&amp;quot;Z =&amp;quot;, Z)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Z = -19.37565463633676
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/output_12_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;convolution-forward-operation&#34;&gt;Convolution forward operation&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/convforward.jpg&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def conv_forward(A_prev, W, b, hparameters):
    &amp;quot;&amp;quot;&amp;quot;
    Implements the forward propagation for a convolution function
    
    Arguments:
    A_prev -- output activations of the previous layer, 
        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)
    b -- Biases, numpy array of shape (1, 1, 1, n_C)
    hparameters -- python dictionary containing &amp;quot;stride&amp;quot; and &amp;quot;pad&amp;quot;
        
    Returns:
    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache of values needed for the conv_backward() function
    &amp;quot;&amp;quot;&amp;quot;
    m, n_H_prev, n_W_prev, n_C_prev =A_prev.shape
    f, f, n_C_prev, n_C =W.shape
    stride=hparameters[&amp;quot;stride&amp;quot;]
    pad =hparameters[&amp;quot;pad&amp;quot;]
    
    #step 1 calculate final n_H , n_w post convolution operation
    n_H = 1+int((n_H_prev+2*pad-f)/stride)
    n_W = 1+int((n_W_prev+2*pad-f)/stride)
    
    #step 2 pad the image
    A_prev_pad=zero_pad(A_prev, pad)
    
    # Initialize the output volume Z with zeros. (≈1 line)
    Z = np.zeros((m,n_H,n_W,n_C))
    A=np.zeros((m,n_H,n_W,n_C))
    
    #step 3 generate sub parts of image for convolution operation for all m training examples
    for i in range(m):
        a_prev_pad=A_prev_pad[i,:,:,:] #get the ith image from m images
        
        for h in range(int(n_H)): #loop over vertical axis of image
            vert_start = h*stride
            vert_end = vert_start+f
            
            for  w in range(int(n_W)):# loop over horizontal axis
                horiz_start = w*stride
                horiz_end = horiz_start+f
                
                for c in range(n_C):# loop over the new no of channels(#filters)
                    #for all the channel in previous image
                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,0:n_C_prev]
                    
                    weights = W[:,:,:,c] #get the value of filter and bias for a particular filter
                    bias =b[:,:,:,c]
                    Z[i,h,w,c]=conv_single_step(a_slice_prev,weights,bias)
                    A[i,h,w,c] =np.where(Z[i,h,w,c]&amp;gt;0,Z[i,h,w,c],0)
                    
        assert(Z.shape==(m,n_H,n_W,n_C))
        
        cache=(A_prev,W,b,hparameters)
        
        return A,cache
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#for the entire image
filter_stack = np.zeros((3,3,3,3))
for i in range(3):
    filter_stack[:,:,:,i]=l1_filter
filter_stack  

A_prev = np.expand_dims(img, axis=0) #10examples, each image of height=5,width=7,no_of channels =4
W = filter_stack#filter of height=3,width=3,no_of channel is same as iamge=4,no of filters=3
b = np.random.randn(1,1,1,3)#bias of size h=1,w=1,depht/no of channel=1,for each filter so 8
hparameters = {&amp;quot;pad&amp;quot; : 1,
               &amp;quot;stride&amp;quot;: 2}

A, cache_conv = conv_forward(A_prev, W, b, hparameters)
plt.imshow(Z[0,:,:,:])

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).





&amp;lt;matplotlib.image.AxesImage at 0x1f4536ad1c8&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/output_16_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;CONV layer should also contain an activation, in which case we would add the following line of code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Convolve the window to get back one output neuron
Z[i, h, w, c] = &amp;hellip;&lt;/li&gt;
&lt;li&gt;Apply activation
A[i, h, w, c] = activation(Z[i, h, w, c])&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pooling-forward&#34;&gt;Pooling forward&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/pooling.jpg&#34; alt=&#34;image.jpg&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def pool_forward(A_prev, hparameters, mode = &amp;quot;max&amp;quot;):
    &amp;quot;&amp;quot;&amp;quot;
    Implements the forward pass of the pooling layer
    
    Arguments:
    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    hparameters -- python dictionary containing &amp;quot;f&amp;quot; and &amp;quot;stride&amp;quot;
    mode -- the pooling mode you would like to use, defined as a string (&amp;quot;max&amp;quot; or &amp;quot;average&amp;quot;)
    
    Returns:
    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters 
    &amp;quot;&amp;quot;&amp;quot;
    
    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape
    stride=hparameters[&amp;quot;stride&amp;quot;]
    f =hparameters[&amp;quot;f&amp;quot;]
    
    #step 1 calculate final n_H , n_w post convolution operation
    n_H = int(1 + (n_H_prev - f) / stride)
    n_W = int(1 + (n_W_prev - f) / stride)
    n_C = n_C_prev
    
    
    # Initialize the output volume Z with zeros. (≈1 line)
    A = np.zeros((m,n_H,n_W,n_C))
    
    #step 3 generate sub parts of image for convolution operation for all m training examples
    for i in range(m):
        a_prev=A_prev[i,:,:,:] #get the ith image from m images
        
        for h in range(int(n_H)): #loop over vertical axis of image
            vert_start = h*stride
            vert_end = vert_start+f
            
            for  w in range(int(n_W)):# loop over horizontal axis
                horiz_start = w*stride
                horiz_end = horiz_start+f
                
                for c in range(n_C):# loop over the new no of channels(#filters)
                    #for all the channel in previous image
                    a_slice_prev = a_prev[vert_start:vert_end,horiz_start:horiz_end,0:n_C_prev]
                    
                    # Compute the pooling operation on the slice. 
                    # Use an if statement to differentiate the modes. 
                    # Use np.max and np.mean.
                    if mode == &amp;quot;max&amp;quot;:
                        A[i, h, w, c] = np.max(a_slice_prev )
                    elif mode == &amp;quot;average&amp;quot;:
                        A[i, h, w, c] = np.mean(a_slice_prev )
                        
                    
        assert(A.shape==(m,n_H,n_W,n_C))
        
        cache=(A_prev,hparameters)
        
        return A,cache
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#stride of 1
np.random.seed(1)
A_prev = A
hparameters = {&amp;quot;stride&amp;quot; : 1, &amp;quot;f&amp;quot;: 3}

fig,axs=plt.subplots(1,2)

A, cache = pool_forward(A_prev, hparameters)
print(&amp;quot;mode = max&amp;quot;)
#print(&amp;quot;A.shape = &amp;quot; + str(A.shape))
#print(&amp;quot;A =\n&amp;quot;, A)
print()
print(A.shape)

axs[0].imshow(A_prev[0,:,:,:])
axs[0].set_title(&#39;A prev&#39;)
axs[1].imshow(A[0,:,:,:])
axs[1].set_title(&#39;max pool&#39;)


&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).


mode = max

(1, 148, 224, 3)





Text(0.5, 1.0, &#39;max pool&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/output_20_3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
A, cache = pool_forward(A_prev, hparameters, mode = &amp;quot;average&amp;quot;)
print(&amp;quot;mode = average&amp;quot;)
#print(&amp;quot;A.shape = &amp;quot; + str(A.shape))
#print(&amp;quot;A =\n&amp;quot;, A)

fig,axs=plt.subplots(1,2)
axs[0].imshow(A_prev[0,:,:,:])
axs[0].set_title(&#39;A prev&#39;)
axs[1].imshow(A[0,:,:,:])
axs[1].set_title(&#39;average pool&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).


mode = average





Text(0.5, 1.0, &#39;average pool&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/output_21_3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#stride of 2
np.random.seed(1)

hparameters = {&amp;quot;stride&amp;quot; : 2, &amp;quot;f&amp;quot;: 3}

fig,axs=plt.subplots(1,2)

A, cache = pool_forward(A_prev, hparameters)
print(&amp;quot;mode = max&amp;quot;)
#print(&amp;quot;A.shape = &amp;quot; + str(A.shape))
#print(&amp;quot;A =\n&amp;quot;, A)
print()

axs[0].imshow(A_prev[0,:,:,:])
axs[0].set_title(&#39;A prev&#39;)
axs[1].imshow(A[0,:,:,:])
axs[1].set_title(&#39;max pool&#39;)


&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).


mode = max






Text(0.5, 1.0, &#39;max pool&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/CNNfromscratch/output_22_3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;put-it-all-together-cnn&#34;&gt;Put it all together (CNN)&lt;/h2&gt;
&lt;p&gt;we will see this in the second part of the post .&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Neural Network from Scratch</title>
      <link>https://richakbee.github.io/post/deep_neural_nets/</link>
      <pubDate>Mon, 28 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://richakbee.github.io/post/deep_neural_nets/</guid>
      <description>&lt;h1 id=&#34;import-libraries&#34;&gt;Import Libraries&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import matplotlib.pyplot as plt
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/DeepNNfromscratch/deepnn.jpg&#34; alt=&#34;image.jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;steps&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Forward Pass&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;initialize parameters (i.e weights &amp;amp; biases)&lt;/li&gt;
&lt;li&gt;caluclate linear forward ( a.k.a Z value)&lt;/li&gt;
&lt;li&gt;calculate linear activation forward ( a.k.a A value)&lt;/li&gt;
&lt;li&gt;calculate forward functions for all L layers&lt;/li&gt;
&lt;li&gt;calculate Cost function&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Backward Pass&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;calculate linear backward ( a.k.a derivatives)&lt;/li&gt;
&lt;li&gt;calculate linear activation backward&lt;/li&gt;
&lt;li&gt;calculate backward functions for all L layers&lt;/li&gt;
&lt;li&gt;update the parameters (i.e weights &amp;amp; biases)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;forward-pass&#34;&gt;Forward Pass&lt;/h2&gt;
&lt;h3 id=&#34;initialize-parameters&#34;&gt;Initialize parameters&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Random initialization to weights &amp;amp; zeros to biases&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def initialize_parameters_deep(layers_dims):
    &amp;quot;&amp;quot;&amp;quot;
    Arguments:
    layer_dims -- python array (list) containing the dimensions of each layer in our network
    
    Returns:
    parameters -- python dictionary containing your parameters &amp;quot;W1&amp;quot;, &amp;quot;b1&amp;quot;, ..., &amp;quot;WL&amp;quot;, &amp;quot;bL&amp;quot;:
                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])
                    bl -- bias vector of shape (layer_dims[l], 1)
    &amp;quot;&amp;quot;&amp;quot;
    
    np.random.seed(3)
    parameters={}
    L=len(layers_dims)
    
    for l in range(1,L):#loop goes from 1 to L-1
        parameters[&amp;quot;W&amp;quot;+str(l)]=np.random.randn(layers_dims[l],layers_dims[l-1])*0.01
        parameters[&amp;quot;b&amp;quot;+str(l)]=np.zeros((layers_dims[l],1))
    
        assert(parameters[&amp;quot;W&amp;quot;+str(l)].shape == (layers_dims[l], layers_dims[l-1]))
        assert(parameters[&amp;quot;b&amp;quot;+str(l)].shape == (layers_dims[l], 1))
    
    return parameters
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;layers_dims = np.array([3, 4,4, 1])
parameters = initialize_parameters_deep(layers_dims)
print(parameters)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&#39;W1&#39;: array([[ 0.01788628,  0.0043651 ,  0.00096497],
       [-0.01863493, -0.00277388, -0.00354759],
       [-0.00082741, -0.00627001, -0.00043818],
       [-0.00477218, -0.01313865,  0.00884622]]), &#39;b1&#39;: array([[0.],
       [0.],
       [0.],
       [0.]]), &#39;W2&#39;: array([[ 0.00881318,  0.01709573,  0.00050034, -0.00404677],
       [-0.0054536 , -0.01546477,  0.00982367, -0.01101068],
       [-0.01185047, -0.0020565 ,  0.01486148,  0.00236716],
       [-0.01023785, -0.00712993,  0.00625245, -0.00160513]]), &#39;b2&#39;: array([[0.],
       [0.],
       [0.],
       [0.]]), &#39;W3&#39;: array([[-0.00768836, -0.00230031,  0.00745056,  0.01976111]]), &#39;b3&#39;: array([[0.]])}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;linear-forward&#34;&gt;Linear Forward&lt;/h3&gt;
&lt;p&gt;The linear forward module (vectorized over all the examples) computes the following equations:&lt;/p&gt;
&lt;p&gt;$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}\tag{4}$$
where $A^{[0]} = X$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def linear_forward(A, W, b):
    &amp;quot;&amp;quot;&amp;quot;
    Implement the linear part of a layer&#39;s forward propagation.

    Arguments:
    A -- activations from previous layer (or input data): (size of previous layer, number of examples)
    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)
    b -- bias vector, numpy array of shape (size of the current layer, 1)

    Returns:
    Z -- the input of the activation function, also called pre-activation parameter 
    cache -- a python tuple containing &amp;quot;A&amp;quot;, &amp;quot;W&amp;quot; and &amp;quot;b&amp;quot; ; stored for computing the backward pass efficiently
    &amp;quot;&amp;quot;&amp;quot;
 
    Z=np.dot(W,A)+b
    
    assert(Z.shape ==(W.shape[0],A.shape[1]))
    cache = (A,W,b)
    
    return Z,cache
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;activation-functions&#34;&gt;Activation functions&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def sigmoid(Z):
    Z=np.array(Z)
    return (1/(1+np.exp(-Z)),Z)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sigmoid([[1,2,3],[1,2,3]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(array([[0.73105858, 0.88079708, 0.95257413],
        [0.73105858, 0.88079708, 0.95257413]]), array([[1, 2, 3],
        [1, 2, 3]]))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def relu(Z):
    Z=np.array(Z)   
    return (np.where(Z&amp;gt;0,Z,0),Z)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;relu([[1,0.8,-3],[-1,2,0]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(array([[1. , 0.8, 0. ],
        [0. , 2. , 0. ]]), array([[ 1. ,  0.8, -3. ],
        [-1. ,  2. ,  0. ]]))
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;linear-activation-forward&#34;&gt;Linear activation forward&lt;/h3&gt;
&lt;p&gt;Sigmoid: $\sigma(Z) = \sigma(W A + b) = \frac{1}{ 1 + e^{-(W A + b)}}$. We have provided you with the sigmoid function. This function returns two items: the activation value &amp;ldquo;a&amp;rdquo; and a &amp;ldquo;cache&amp;rdquo; that contains &amp;ldquo;Z&amp;rdquo; (it&amp;rsquo;s what we will feed in to the corresponding backward function). To use it you could just call:&lt;/p&gt;
&lt;p&gt;A, activation_cache = sigmoid(Z)
ReLU: The mathematical formula for ReLu is $A = RELU(Z) = max(0, Z)$. We have provided you with the relu function. This function returns two items: the activation value &amp;ldquo;A&amp;rdquo; and a &amp;ldquo;cache&amp;rdquo; that contains &amp;ldquo;Z&amp;rdquo; (it&amp;rsquo;s what we will feed in to the corresponding backward function). To use it you could just call:&lt;/p&gt;
&lt;p&gt;A, activation_cache = relu(Z)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def linear_activation_forward(A_prev, W, b, activation):
    &amp;quot;&amp;quot;&amp;quot;
    Implement the forward propagation for the LINEAR-&amp;gt;ACTIVATION layer

    Arguments:
    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)
    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)
    b -- bias vector, numpy array of shape (size of the current layer, 1)
    activation -- the activation to be used in this layer, stored as a text string: &amp;quot;sigmoid&amp;quot; or &amp;quot;relu&amp;quot;

    Returns:
    A -- the output of the activation function, also called the post-activation value 
    cache -- a python tuple containing &amp;quot;linear_cache&amp;quot; and &amp;quot;activation_cache&amp;quot;;
             stored for computing the backward pass efficiently
    &amp;quot;&amp;quot;&amp;quot;
    
    if activation==&#39;sigmoid&#39;:
        Z,linear_cache = linear_forward(A_prev, W, b)
        A , activation_cache = sigmoid(Z) 
        
    if activation==&#39;relu&#39;:
        Z,linear_cache = linear_forward(A_prev, W, b)
        A ,activation_cache = relu(Z)    
        
    assert (A.shape == (W.shape[0], A_prev.shape[1]))
    cache = (linear_cache, activation_cache)

    return A, cache    
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;l-model-forward&#34;&gt;L Model forward&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def L_model_forward(X, parameters):
    &amp;quot;&amp;quot;&amp;quot;
    Implement forward propagation for the [LINEAR-&amp;gt;RELU]*(L-1)-&amp;gt;LINEAR-&amp;gt;SIGMOID computation
    
    Arguments:
    X -- data, numpy array of shape (input size, number of examples)
    parameters -- output of initialize_parameters_deep()
    
    Returns:
    AL -- last post-activation value
    caches -- list of caches containing:
                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)
    &amp;quot;&amp;quot;&amp;quot;
    AL=[]
    A=X
    caches=[]
    L=len(parameters)//2
    
    for l in range(1,L):
       
        A_prev =A
       
        A, cache = linear_activation_forward(A_prev,parameters[&amp;quot;W&amp;quot;+str(l)],parameters[&amp;quot;b&amp;quot;+str(l)],&amp;quot;relu&amp;quot;)
        caches.append(cache)
        
        
        
    AL , cache=linear_activation_forward(A,parameters[&amp;quot;W&amp;quot;+str(L)],parameters[&amp;quot;b&amp;quot;+str(L)],&amp;quot;sigmoid&amp;quot;)
    caches.append(cache)
    
    assert(AL.shape ==(1,X.shape[1]))
    return AL,caches
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;cost-function&#34;&gt;Cost Function&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def compute_cost(AL,Y):
    &amp;quot;&amp;quot;&amp;quot;
    Implement the cost function defined by equation (7).

    Arguments:
    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)
    Y -- true &amp;quot;label&amp;quot; vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)

    Returns:
    cost -- cross-entropy cost
    &amp;quot;&amp;quot;&amp;quot;
    m = Y.shape[1]
    
    cost = -1/m*np.sum(Y*np.log(AL)+(1-Y)*np.log((1-AL)))

    
    cost = np.squeeze(cost) # To make sure your cost&#39;s shape is what we expect (e.g. this turns [[17]] into 17).
    assert(cost.shape == ())
    
    return cost
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;backward-pass&#34;&gt;Backward Pass&lt;/h2&gt;
&lt;h3 id=&#34;linear-backward&#34;&gt;Linear Backward&lt;/h3&gt;
&lt;p&gt;For layer $l$, the linear part is: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$ (followed by an activation).&lt;/p&gt;
&lt;p&gt;Suppose you have already calculated the derivative $dZ^{[l]} = \frac{\partial \mathcal{L} }{\partial Z^{[l]}}$. You want to get $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/DeepNNfromscratch/linback.jpg&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The three outputs $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$ are computed using the input $dZ^{[l]}$ (using formulae above).&lt;/p&gt;
&lt;!-- Here are the formulas you need:
$$ dW^{[l]} = \frac{\partial \mathcal{J} }{\partial W^{[l]}} = \frac{1}{m} dZ^{[l]} A^{[l-1] T} \tag{8}$$ $$ db^{[l]} = \frac{\partial \mathcal{J} }{\partial b^{[l]}} = \frac{1}{m} \sum_{i = 1}^{m} dZ^{[l](i)}tag{9}$$
$$ dA^{[l-1]} = \frac{\partial \mathcal{L} }{\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} \tag{10}$$ --&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def linear_backward(dZ,cache):
    &amp;quot;&amp;quot;&amp;quot;
    Implement the linear portion of backward propagation for a single layer (layer l)

    Arguments:
    dZ -- Gradient of the cost with respect to the linear output (of current layer l)
    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer

    Returns:
    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev
    dW -- Gradient of the cost with respect to W (current layer l), same shape as W
    db -- Gradient of the cost with respect to b (current layer l), same shape as b
    &amp;quot;&amp;quot;&amp;quot;
    A_prev, W, b = cache
    m = A_prev.shape[1]
    
    dW = 1/m*np.dot(dZ,A_prev.T)
    db =1/m*np.sum(dZ,axis=1,keepdims=True)
    dA_prev =np.dot(W.T,dZ)
    
    assert(dA_prev.shape == A_prev.shape)
    assert(dW.shape == W.shape)
    assert(db.shape == b.shape)
    
    return dA_prev, dW, db
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;backward-activation-functions&#34;&gt;Backward activation functions&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def sigmoid_backward(dA, activation_cache):
    &amp;quot;&amp;quot;&amp;quot;
    activation_cache= Z
    &amp;quot;&amp;quot;&amp;quot;
    Z=np.array(activation_cache) 
    val=1/(1+np.exp(-Z))
    return (dA*val*(1-val))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sigmoid_backward([[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;array([[0.19661193, 0.20998717, 0.13552998],
       [0.19661193, 0.20998717, 0.13552998]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def relu_backward(dA, activation_cache):
    &amp;quot;&amp;quot;&amp;quot;
    activation_cache= Z
    &amp;quot;&amp;quot;&amp;quot;
    Z=np.array(activation_cache)
    return (dA*np.where(Z&amp;gt;0,1,0))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;relu_backward([[1,2,3],[1,2,3]],[[1,0.8,-3],[-1,2,0]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;array([[1, 2, 0],
       [0, 2, 0]])
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;linear-activation-backward&#34;&gt;Linear activation backward&lt;/h3&gt;
&lt;p&gt;To help  implement linear_activation_backward, we provided two backward functions:&lt;/p&gt;
&lt;p&gt;sigmoid_backward: Implements the backward propagation for SIGMOID unit. You can call it as follows:
dZ = sigmoid_backward(dA, activation_cache)
relu_backward: Implements the backward propagation for RELU unit. You can call it as follows:
dZ = relu_backward(dA, activation_cache)
If $g(.)$ is the activation function, sigmoid_backward and relu_backward compute$$dZ^{[l]} = dA^{[l]} * g&#39;(Z^{[l]}) \tag{11}$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def linear_activation_backward(dA, cache, activation):
    &amp;quot;&amp;quot;&amp;quot;
    Implement the backward propagation for the LINEAR-&amp;gt;ACTIVATION layer.
    
    Arguments:
    dA -- post-activation gradient for current layer l 
    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently
    activation -- the activation to be used in this layer, stored as a text string: &amp;quot;sigmoid&amp;quot; or &amp;quot;relu&amp;quot;
    
    Returns:
    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev
    dW -- Gradient of the cost with respect to W (current layer l), same shape as W
    db -- Gradient of the cost with respect to b (current layer l), same shape as b
    &amp;quot;&amp;quot;&amp;quot;
    linear_cache, activation_cache = cache
    
    if activation == &amp;quot;sigmoid&amp;quot;: 
        dZ =sigmoid_backward(dA, activation_cache)
        dA_prev, dW, db = linear_backward(dZ, linear_cache)
      
    elif activation == &amp;quot;relu&amp;quot;:
        dZ = relu_backward(dA, activation_cache)
        dA_prev, dW, db = linear_backward(dZ, linear_cache)
    
    return dA_prev, dW, db
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;l-model-backward&#34;&gt;L model backward&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def L_model_backward(AL, Y, caches):
    &amp;quot;&amp;quot;&amp;quot;
    Implement the backward propagation for the [LINEAR-&amp;gt;RELU] * (L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID group
    
    Arguments:
    AL -- probability vector, output of the forward propagation (L_model_forward())
    Y -- true &amp;quot;label&amp;quot; vector (containing 0 if non-cat, 1 if cat)
    caches -- list of caches containing:
                every cache of linear_activation_forward() with &amp;quot;relu&amp;quot; (it&#39;s caches[l], for l in range(L-1) i.e l = 0...L-2)
                the cache of linear_activation_forward() with &amp;quot;sigmoid&amp;quot; (it&#39;s caches[L-1])
    
    Returns:
    grads -- A dictionary with the gradients
             grads[&amp;quot;dA&amp;quot; + str(l)] = ... 
             grads[&amp;quot;dW&amp;quot; + str(l)] = ...
             grads[&amp;quot;db&amp;quot; + str(l)] = ... 
    &amp;quot;&amp;quot;&amp;quot;
    grads = {}
    L = len(caches) # the number of layers
    m = AL.shape[1]
    Y = Y.reshape(AL.shape)# after this line, Y is the same shape as AL
    
    # Initializing the backpropagation
    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))
    
    ###Lth layer (SIGMOID -&amp;gt; LINEAR) gradients. Inputs: &amp;quot;dAL, current_cache&amp;quot;. 
    ###Outputs: &amp;quot;grads[&amp;quot;dAL-1&amp;quot;], grads[&amp;quot;dWL&amp;quot;], grads[&amp;quot;dbL&amp;quot;]
    current_cache = caches[L-1]
    grads[&amp;quot;dA&amp;quot; + str(L-1)], grads[&amp;quot;dW&amp;quot; + str(L)], grads[&amp;quot;db&amp;quot; + str(L)] =linear_activation_backward(dAL, current_cache, &amp;quot;sigmoid&amp;quot;)
    
    # Loop from l=L-2 to l=0
    for l in reversed(range(L-1)):
        # lth layer: (RELU -&amp;gt; LINEAR) gradients.
        # Inputs: &amp;quot;grads[&amp;quot;dA&amp;quot; + str(l + 1)], current_cache&amp;quot;. 
        ###Outputs: &amp;quot;grads[&amp;quot;dA&amp;quot; + str(l)] , grads[&amp;quot;dW&amp;quot; + str(l + 1)] , grads[&amp;quot;db&amp;quot; + str(l + 1)] 
        ### START CODE HERE ### (approx. 5 lines)
        current_cache =caches[l]
        dA_prev_temp, dW_temp, db_temp =linear_activation_backward(grads[&amp;quot;dA&amp;quot; + str(l+1)], current_cache, activation = &amp;quot;relu&amp;quot;)
        grads[&amp;quot;dA&amp;quot; + str(l)] = dA_prev_temp
        grads[&amp;quot;dW&amp;quot; + str(l + 1)] = dW_temp
        grads[&amp;quot;db&amp;quot; + str(l + 1)] =db_temp 
        
    return grads  
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;update-parameters&#34;&gt;Update Parameters&lt;/h3&gt;
&lt;p&gt;update the parameters of the model, using gradient descent:&lt;/p&gt;
&lt;p&gt;$$ W^{[l]} = W^{[l]} - \alpha \text{ } dW^{[l]} $$$$ b^{[l]} = b^{[l]} - \alpha \text{ } db^{[l]} $$
where $\alpha$ is the learning rate. After computing the updated parameters, store them in the parameters dictionary.&lt;/p&gt;
&lt;p&gt;Implement update_parameters() to update your parameters using gradient descent.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def update_parameters(parameters, grads, learning_rate):  
    
    L = len(parameters) // 2 # number of layers in the neural network
    
    # Update rule for each parameter.
   
    for l in range(L):
        parameters[&amp;quot;W&amp;quot; + str(l+1)] = parameters[&amp;quot;W&amp;quot; + str(l+1)]-learning_rate*grads[&amp;quot;dW&amp;quot; + str(l+1)]
        parameters[&amp;quot;b&amp;quot; + str(l+1)] =  parameters[&amp;quot;b&amp;quot; + str(l+1)]-learning_rate*grads[&amp;quot;db&amp;quot; + str(l+1)]
        
  
  
    return parameters
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;l-layer-neural-networkfinal&#34;&gt;L-layer neural network(Final)&lt;/h1&gt;
&lt;p&gt;Question: Use the helper functions you have implemented in the previous assignment to build a 2-layer neural network with the following structure: LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SIGMOID. The functions you may need and their inputs are:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/DeepNNfromscratch/funcsteps.jpg&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):
    &amp;quot;&amp;quot;&amp;quot;
    Implements a L-layer neural network: [LINEAR-&amp;gt;RELU]*(L-1)-&amp;gt;LINEAR-&amp;gt;SIGMOID.
    
    Arguments:
    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)
    Y -- true &amp;quot;label&amp;quot; vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)
    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).
    learning_rate -- learning rate of the gradient descent update rule
    num_iterations -- number of iterations of the optimization loop
    print_cost -- if True, it prints the cost every 100 steps
    
    Returns:
    parameters -- parameters learnt by the model. They can then be used to predict.
    &amp;quot;&amp;quot;&amp;quot;

    np.random.seed(3)
    costs = []                             # to keep track of the cost
    
    
    # Initialize parameters dictionary
    parameters = initialize_parameters_deep(layers_dims)
        
   # Loop (gradient descent)

    for i in range(0, num_iterations):
         # Forward propagation: 
        #[LINEAR -&amp;gt; RELU]*(L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID.
        AL, caches =  L_model_forward(X, parameters)

        
        # Compute cost
        cost = compute_cost(AL, Y)

        # Backward propagation.
        grads = L_model_backward(AL, Y, caches)
        
         # Update parameters.
        
        ### START CODE HERE ### (approx. 1 line of code)
        parameters = update_parameters(parameters, grads, learning_rate)
           
        if print_cost and i % 100 == 0:
            print(&amp;quot;Cost after iteration {}: {}&amp;quot;.format(i, np.squeeze(cost)))
        if print_cost and i % 100 == 0:
            costs.append(cost)
    
    plt.plot(np.squeeze(costs))
    plt.ylabel(&#39;cost&#39;)
    plt.xlabel(&#39;iterations (per hundreds)&#39;)
    plt.title(&amp;quot;Learning rate =&amp;quot; + str(learning_rate))
    plt.show()
    
    return parameters
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;implement-4-layer-neural-network&#34;&gt;Implement 4-layer neural network&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;layers_dims = ([3,4,5,2,1])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;X=np.random.randn(3,150)
Y=[]
for i in range(150):
    Y.append(np.random.randint(0,2))
Y=np.array(Y)    
Y=np.reshape(Y,(1,150))
print(X.shape,Y.shape)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(3, 150) (1, 150)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Cost after iteration 0: 0.693147179101668
Cost after iteration 100: 0.6913663615472958
Cost after iteration 200: 0.6901428329273512
Cost after iteration 300: 0.6893019578750604
Cost after iteration 400: 0.6887238512106988
.
.
.
.
.
.
Cost after iteration 2700: 0.6874476979055951
Cost after iteration 2800: 0.6874476213206875
Cost after iteration 2900: 0.6874475684872733
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://richakbee.github.io/images/DeepNNfromscratch/output_40_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; #looking at the parameters learnt
{&#39;W1&#39;: array([[ 0.01788646,  0.00436687,  0.00096225],
        [-0.01863628, -0.00277482, -0.00354674],
        [-0.00082677, -0.00627067, -0.00043808],
        [-0.00476898, -0.01314048,  0.00884857]]),
 &#39;b1&#39;: array([[-2.64082146e-07],
        [ 2.72834707e-07],
        [ 3.64257323e-07],
        [ 1.75856439e-06]]),
 &#39;W2&#39;: array([[ 0.0088149 ,  0.01709711,  0.00049992, -0.00404753],
        [-0.0054536 , -0.01546477,  0.00982367, -0.01101068],
        [-0.01185051, -0.00205634,  0.01486141,  0.00236701],
        [-0.01023786, -0.00712985,  0.00625262, -0.00160502],
        [-0.00768738, -0.00230125,  0.00745106,  0.01976248]]),
 &#39;b2&#39;: array([[ 2.34080642e-05],
        [ 0.00000000e+00],
        [-2.81738458e-06],
        [ 1.85347160e-05],
        [ 8.13445992e-05]]),
 &#39;W3&#39;: array([[-0.01244123, -0.00626417, -0.00803766, -0.02419083, -0.00923792],
        [-0.01024285,  0.01123978, -0.00131827, -0.01623289,  0.0064712 ]]),
 &#39;b3&#39;: array([[0.        ],
        [0.00374547]]),
 &#39;W4&#39;: array([[-0.00356271, -0.01783282]]),
 &#39;b4&#39;: array([[-0.21327127]])}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Resturant reviews with nltk</title>
      <link>https://richakbee.github.io/post/nlp-demo/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://richakbee.github.io/post/nlp-demo/</guid>
      <description>&lt;h2 id=&#34;importing-the-libraries&#34;&gt;Importing the libraries&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;importing-the-dataset&#34;&gt;Importing the dataset&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dataset = pd.read_csv(&#39;Restaurant_Reviews.tsv&#39;, delimiter = &#39;\t&#39;, quoting = 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;cleaning-the-texts&#34;&gt;Cleaning the texts&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re
import nltk
nltk.download(&#39;stopwords&#39;)
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
corpus = []
for i in range(0, 1000):
  review = re.sub(&#39;[^a-zA-Z]&#39;, &#39; &#39;, dataset[&#39;Review&#39;][i])
  review = review.lower()
  review = review.split()
  ps = PorterStemmer()
  all_stopwords = stopwords.words(&#39;english&#39;)
  all_stopwords.remove(&#39;not&#39;)
  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]
  review = &#39; &#39;.join(review)
  corpus.append(review)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(corpus)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[&#39;wow love place&#39;, &#39;crust not good&#39;, &#39;not tasti textur nasti&#39;, &#39;stop late may bank holiday rick steve recommend love&#39;, &#39;select menu great price&#39;, &#39;get angri want damn pho&#39;, &#39;honeslti tast fresh&#39;, &#39;potato like rubber could tell made ahead time kept warmer&#39;, &#39;fri great&#39;, &#39;great touch&#39;, &#39;servic prompt&#39;, &#39;would not go back&#39;, &#39;cashier care ever say still end wayyy overpr&#39;, &#39;tri cape cod ravoli chicken cranberri mmmm&#39;, &#39;disgust pretti sure human hair&#39;, &#39;shock sign indic cash&#39;, &#39;highli recommend&#39;, &#39;waitress littl slow servic&#39;, &#39;place not worth time let alon vega&#39;, &#39;not like&#39;, &#39;burritto blah&#39;, &#39;food amaz&#39;, &#39;servic also cute&#39;, &#39;could care less interior beauti&#39;, &#39;perform&#39;, &#39;right red velvet cake ohhh stuff good&#39;, &#39;never brought salad ask&#39;, &#39;hole wall great mexican street taco friendli staff&#39;, &#39;took hour get food tabl restaur food luke warm sever run around like total overwhelm&#39;, &#39;worst salmon sashimi&#39;, &#39;also combo like burger fri beer decent deal&#39;, &#39;like final blow&#39;, &#39;found place accid could not happier&#39;, &#39;seem like good quick place grab bite familiar pub food favor look elsewher&#39;, &#39;overal like place lot&#39;, &#39;redeem qualiti restaur inexpens&#39;, &#39;ampl portion good price&#39;, &#39;poor servic waiter made feel like stupid everi time came tabl&#39;, &#39;first visit hiro delight&#39;, &#39;servic suck&#39;, &#39;shrimp tender moist&#39;, &#39;not deal good enough would drag establish&#39;, &#39;hard judg whether side good gross melt styrofoam want eat fear get sick&#39;, &#39;posit note server attent provid great servic&#39;, &#39;frozen puck disgust worst peopl behind regist&#39;, &#39;thing like prime rib dessert section&#39;, &#39;bad food damn gener&#39;, &#39;burger good beef cook right&#39;, &#39;want sandwich go firehous&#39;, &#39;side greek salad greek dress tasti pita hummu refresh&#39;, &#39;order duck rare pink tender insid nice char outsid&#39;, &#39;came run us realiz husband left sunglass tabl&#39;, &#39;chow mein good&#39;, &#39;horribl attitud toward custom talk one custom enjoy food&#39;, &#39;portion huge&#39;, &#39;love friendli server great food wonder imagin menu&#39;, &#39;heart attack grill downtown vega absolut flat line excus restaur&#39;, &#39;not much seafood like string pasta bottom&#39;, &#39;salad right amount sauc not power scallop perfectli cook&#39;, &#39;rip banana not rip petrifi tasteless&#39;, &#39;least think refil water struggl wave minut&#39;, &#39;place receiv star appet&#39;, &#39;cocktail handmad delici&#39;, &#39;definit go back&#39;, &#39;glad found place&#39;, &#39;great food servic huge portion give militari discount&#39;, &#39;alway great time do gringo&#39;, &#39;updat went back second time still amaz&#39;, &#39;got food appar never heard salt batter fish chewi&#39;, &#39;great way finish great&#39;, &#39;deal includ tast drink jeff went beyond expect&#39;, &#39;realli realli good rice time&#39;, &#39;servic meh&#39;, &#39;took min get milkshak noth chocol milk&#39;, &#39;guess known place would suck insid excalibur use common sens&#39;, &#39;scallop dish quit appal valu well&#39;, &#39;time bad custom servic&#39;, &#39;sweet potato fri good season well&#39;, &#39;today second time lunch buffet pretti good&#39;, &#39;much good food vega feel cheat wast eat opportun go rice compani&#39;, &#39;come like experienc underwhelm relationship parti wait person ask break&#39;, &#39;walk place smell like old greas trap other eat&#39;, &#39;turkey roast beef bland&#39;, &#39;place&#39;, &#39;pan cake everyon rave tast like sugari disast tailor palat six year old&#39;, &#39;love pho spring roll oh yummi tri&#39;, &#39;poor batter meat ratio made chicken tender unsatisfi&#39;, &#39;say food amaz&#39;, &#39;omelet die&#39;, &#39;everyth fresh delici&#39;, &#39;summari larg disappoint dine experi&#39;, &#39;like realli sexi parti mouth outrag flirt hottest person parti&#39;, &#39;never hard rock casino never ever step forward&#39;, &#39;best breakfast buffet&#39;, &#39;say bye bye tip ladi&#39;, &#39;never go&#39;, &#39;back&#39;, &#39;food arriv quickli&#39;, &#39;not good&#39;, &#39;side cafe serv realli good food&#39;, &#39;server fantast found wife love roast garlic bone marrow ad extra meal anoth marrow go&#39;, &#39;good thing waiter help kept bloddi mari come&#39;, &#39;best buffet town price cannot beat&#39;, &#39;love mussel cook wine reduct duck tender potato dish delici&#39;, &#39;one better buffet&#39;, &#39;went tigerlilli fantast afternoon&#39;, &#39;food delici bartend attent person got great deal&#39;, &#39;ambienc wonder music play&#39;, &#39;go back next trip&#39;, &#39;sooooo good&#39;, &#39;real sushi lover let honest yama not good&#39;, &#39;least min pass us order food arriv busi&#39;, &#39;realli fantast thai restaur definit worth visit&#39;, &#39;nice spici tender&#39;, &#39;good price&#39;, &#39;check&#39;, &#39;pretti gross&#39;, &#39;better atmospher&#39;, &#39;kind hard mess steak&#39;, &#39;although much like look sound place actual experi bit disappoint&#39;, &#39;know place manag serv blandest food ever eaten prepar indian cuisin&#39;, &#39;worst servic boot least worri&#39;, &#39;servic fine waitress friendli&#39;, &#39;guy steak steak love son steak best worst place said best steak ever eaten&#39;, &#39;thought ventur away get good sushi place realli hit spot night&#39;, &#39;host staff lack better word bitch&#39;, &#39;bland not like place number reason want wast time bad review leav&#39;, &#39;phenomen food servic ambianc&#39;, &#39;return&#39;, &#39;definit worth ventur strip pork belli return next time vega&#39;, &#39;place way overpr mediocr food&#39;, &#39;penn vodka excel&#39;, &#39;good select food includ massiv meatloaf sandwich crispi chicken wrap delish tuna melt tasti burger&#39;, &#39;manag rude&#39;, &#39;delici nyc bagel good select cream chees real lox caper even&#39;, &#39;great subway fact good come everi subway not meet expect&#39;, &#39;serious solid breakfast&#39;, &#39;one best bar food vega&#39;, &#39;extrem rude realli mani restaur would love dine weekend vega&#39;, &#39;drink never empti made realli great menu suggest&#39;, &#39;&#39;, &#39;waiter help friendli rare check us&#39;, &#39;husband ate lunch disappoint food servic&#39;, &#39;red curri much bamboo shoot tasti&#39;, &#39;nice blanket moz top feel like done cover subpar food&#39;, &#39;bathroom clean place well decor&#39;, &#39;menu alway chang food qualiti go servic extrem slow&#39;, &#39;servic littl slow consid serv peopl server food come slow pace&#39;, &#39;give thumb&#39;, &#39;watch waiter pay lot attent tabl ignor us&#39;, &#39;fianc came middl day greet seat right away&#39;, &#39;great restaur mandalay bay&#39;, &#39;wait forti five minut vain&#39;, &#39;crostini came salad stale&#39;, &#39;highlight great qualiti nigiri&#39;, &#39;staff friendli joint alway clean&#39;, &#39;differ cut piec day still wonder tender well well flavor&#39;, &#39;order voodoo pasta first time realli excel pasta sinc go gluten free sever year ago&#39;, &#39;place good&#39;, &#39;unfortun must hit bakeri leftov day everyth order stale&#39;, &#39;came back today sinc reloc still not impress&#39;, &#39;seat immedi&#39;, &#39;menu divers reason price&#39;, &#39;avoid cost&#39;, &#39;restaur alway full never wait&#39;, &#39;delici&#39;, &#39;place hand one best place eat phoenix metro area&#39;, &#39;go look good food&#39;, &#39;never treat bad&#39;, &#39;bacon hella salti&#39;, &#39;also order spinach avocado salad ingredi sad dress liter zero tast&#39;, &#39;realli vega fine dine use right menu hand ladi price list&#39;, &#39;waitress friendli&#39;, &#39;lordi khao soi dish not miss curri lover&#39;, &#39;everyth menu terrif also thrill made amaz accommod vegetarian daughter&#39;, &#39;perhap caught night judg review not inspir go back&#39;, &#39;servic leav lot desir&#39;, &#39;atmospher modern hip maintain touch cozi&#39;, &#39;not weekli haunt definit place come back everi&#39;, &#39;liter sat minut one ask take order&#39;, &#39;burger absolut flavor meat total bland burger overcook charcoal flavor&#39;, &#39;also decid not send back waitress look like verg heart attack&#39;, &#39;dress treat rude&#39;, &#39;probabl dirt&#39;, &#39;love place hit spot want someth healthi not lack quantiti flavor&#39;, &#39;order lemon raspberri ice cocktail also incred&#39;, &#39;food suck expect suck could imagin&#39;, &#39;interest decor&#39;, &#39;realli like crepe station&#39;, &#39;also serv hot bread butter home made potato chip bacon bit top origin good&#39;, &#39;watch prepar delici food&#39;, &#39;egg roll fantast&#39;, &#39;order arriv one gyro miss&#39;, &#39;salad wing ice cream dessert left feel quit satisfi&#39;, &#39;not realli sure joey vote best hot dog valley reader phoenix magazin&#39;, &#39;best place go tasti bowl pho&#39;, &#39;live music friday total blow&#39;, &#39;never insult felt disrespect&#39;, &#39;friendli staff&#39;, &#39;worth drive&#39;, &#39;heard good thing place exceed everi hope could dream&#39;, &#39;food great serivc&#39;, &#39;warm beer help&#39;, &#39;great brunch spot&#39;, &#39;servic friendli invit&#39;, &#39;good lunch spot&#39;, &#39;live sinc first last time step foot place&#39;, &#39;worst experi ever&#39;, &#39;must night place&#39;, &#39;side delish mix mushroom yukon gold pure white corn beateou&#39;, &#39;bug never show would given sure side wall bug climb kitchen&#39;, &#39;minut wait salad realiz come time soon&#39;, &#39;friend love salmon tartar&#39;, &#39;go back&#39;, &#39;extrem tasti&#39;, &#39;waitress good though&#39;, &#39;soggi not good&#39;, &#39;jamaican mojito delici&#39;, &#39;small not worth price&#39;, &#39;food rich order accordingli&#39;, &#39;shower area outsid rins not take full shower unless mind nude everyon see&#39;, &#39;servic bit lack&#39;, &#39;lobster bisqu bussel sprout risotto filet need salt pepper cours none tabl&#39;, &#39;hope bode go busi someon cook come&#39;, &#39;either cold not enough flavor bad&#39;, &#39;love bacon wrap date&#39;, &#39;unbeliev bargain&#39;, &#39;folk otto alway make us feel welcom special&#39;, &#39;main also uninspir&#39;, &#39;place first pho amaz&#39;, &#39;wonder experi made place must stop whenev town&#39;, &#39;food bad enough enjoy deal world worst annoy drunk peopl&#39;, &#39;fun chef&#39;, &#39;order doubl cheeseburg got singl patti fall apart pictur upload yeah still suck&#39;, &#39;great place coupl drink watch sport event wall cover tv&#39;, &#39;possibl give zero star&#39;, &#39;descript said yum yum sauc anoth said eel sauc yet anoth said spici mayo well none roll sauc&#39;, &#39;say would hardest decis honestli dish tast suppos tast amaz&#39;, &#39;not roll eye may stay not sure go back tri&#39;, &#39;everyon attent provid excel custom servic&#39;, &#39;horribl wast time money&#39;, &#39;dish quit flavour&#39;, &#39;time side restaur almost empti excus&#39;, &#39;busi either also build freez cold&#39;, &#39;like review said pay eat place&#39;, &#39;drink took close minut come one point&#39;, &#39;serious flavor delight folk&#39;, &#39;much better ayc sushi place went vega&#39;, &#39;light dark enough set mood&#39;, &#39;base sub par servic receiv effort show gratitud busi go back&#39;, &#39;owner realli great peopl&#39;, &#39;noth privileg work eat&#39;, &#39;greek dress creami flavor&#39;, &#39;overal think would take parent place made similar complaint silent felt&#39;, &#39;pizza good peanut sauc tasti&#39;, &#39;tabl servic pretti fast&#39;, &#39;fantast servic&#39;, &#39;well would given godfath zero star possibl&#39;, &#39;know make&#39;, &#39;tough short flavor&#39;, &#39;hope place stick around&#39;, &#39;bar vega not ever recal charg tap water&#39;, &#39;restaur atmospher exquisit&#39;, &#39;good servic clean inexpens boot&#39;, &#39;seafood fresh gener portion&#39;, &#39;plu buck&#39;, &#39;servic not par either&#39;, &#39;thu far visit twice food absolut delici time&#39;, &#39;good year ago&#39;, &#39;self proclaim coffe cafe wildli disappoint&#39;, &#39;veggitarian platter world&#39;, &#39;cant go wrong food&#39;, &#39;beat&#39;, &#39;stop place madison ironman friendli kind staff&#39;, &#39;chef friendli good job&#39;, &#39;better not dedic boba tea spot even jenni pho&#39;, &#39;like patio servic outstand&#39;, &#39;goat taco skimp meat wow flavor&#39;, &#39;think not&#39;, &#39;mac salad pretti bland not get&#39;, &#39;went bachi burger friend recommend not disappoint&#39;, &#39;servic stink&#39;, &#39;wait wait&#39;, &#39;place not qualiti sushi not qualiti restaur&#39;, &#39;would definit recommend wing well pizza&#39;, &#39;great pizza salad&#39;, &#39;thing went wrong burn saganaki&#39;, &#39;wait hour breakfast could done time better home&#39;, &#39;place amaz&#39;, &#39;hate disagre fellow yelper husband disappoint place&#39;, &#39;wait hour never got either pizza mani around us came later&#39;, &#39;know slow&#39;, &#39;staff great food delish incred beer select&#39;, &#39;live neighborhood disappoint back conveni locat&#39;, &#39;know pull pork could soooo delici&#39;, &#39;get incred fresh fish prepar care&#39;, &#39;go gave star rate pleas know third time eat bachi burger write review&#39;, &#39;love fact everyth menu worth&#39;, &#39;never dine place&#39;, &#39;food excel servic good&#39;, &#39;good beer drink select good food select&#39;, &#39;pleas stay away shrimp stir fri noodl&#39;, &#39;potato chip order sad could probabl count mani chip box probabl around&#39;, &#39;food realli bore&#39;, &#39;good servic check&#39;, &#39;greedi corpor never see anoth dime&#39;, &#39;never ever go back&#39;, &#39;much like go back get pass atroci servic never return&#39;, &#39;summer dine charm outdoor patio delight&#39;, &#39;not expect good&#39;, &#39;fantast food&#39;, &#39;order toast english muffin came untoast&#39;, &#39;food good&#39;, &#39;never go back&#39;, &#39;great food price high qualiti hous made&#39;, &#39;bu boy hand rude&#39;, &#39;point friend basic figur place joke mind make publicli loudli known&#39;, &#39;back good bbq lighter fare reason price tell public back old way&#39;, &#39;consid two us left full happi go wrong&#39;, &#39;bread made hous&#39;, &#39;downsid servic&#39;, &#39;also fri without doubt worst fri ever&#39;, &#39;servic except food good review&#39;, &#39;coupl month later return amaz meal&#39;, &#39;favorit place town shawarrrrrrma&#39;, &#39;black eye pea sweet potato unreal&#39;, &#39;disappoint&#39;, &#39;could serv vinaigrett may make better overal dish still good&#39;, &#39;go far mani place never seen restaur serv egg breakfast especi&#39;, &#39;mom got home immedi got sick bite salad&#39;, &#39;server not pleasant deal alway honor pizza hut coupon&#39;, &#39;truli unbeliev good glad went back&#39;, &#39;fantast servic pleas atmospher&#39;, &#39;everyth gross&#39;, &#39;love place&#39;, &#39;great servic food&#39;, &#39;first bathroom locat dirti seat cover not replenish plain yucki&#39;, &#39;burger got gold standard burger kind disappoint&#39;, &#39;omg food delicioso&#39;, &#39;noth authent place&#39;, &#39;spaghetti noth special whatsoev&#39;, &#39;dish salmon best great&#39;, &#39;veget fresh sauc feel like authent thai&#39;, &#39;worth drive tucson&#39;, &#39;select probabl worst seen vega none&#39;, &#39;pretti good beer select&#39;, &#39;place like chipotl better&#39;, &#39;classi warm atmospher fun fresh appet succul steak basebal steak&#39;, &#39;star brick oven bread app&#39;, &#39;eaten multipl time time food delici&#39;, &#39;sat anoth ten minut final gave left&#39;, &#39;terribl&#39;, &#39;everyon treat equal special&#39;, &#39;take min pancak egg&#39;, &#39;delici&#39;, &#39;good side staff genuin pleasant enthusiast real treat&#39;, &#39;sadli gordon ramsey steak place shall sharpli avoid next trip vega&#39;, &#39;alway even wonder food delici&#39;, &#39;best fish ever life&#39;, &#39;bathroom next door nice&#39;, &#39;buffet small food offer bland&#39;, &#39;outstand littl restaur best food ever tast&#39;, &#39;pretti cool would say&#39;, &#39;definit turn doubt back unless someon els buy&#39;, &#39;server great job handl larg rowdi tabl&#39;, &#39;find wast food despic food&#39;, &#39;wife lobster bisqu soup lukewarm&#39;, &#39;would come back sushi crave vega&#39;, &#39;staff great ambianc great&#39;, &#39;deserv star&#39;, &#39;left stomach ach felt sick rest day&#39;, &#39;drop ball&#39;, &#39;dine space tini elegantli decor comfort&#39;, &#39;custom order way like usual eggplant green bean stir fri love&#39;, &#39;bean rice mediocr best&#39;, &#39;best taco town far&#39;, &#39;took back money got outta&#39;, &#39;interest part town place amaz&#39;, &#39;rude inconsider manag&#39;, &#39;staff not friendli wait time serv horribl one even say hi first minut&#39;, &#39;back&#39;, &#39;great dinner&#39;, &#39;servic outshin definit recommend halibut&#39;, &#39;food terribl&#39;, &#39;never ever go back told mani peopl happen&#39;, &#39;recommend unless car break front starv&#39;, &#39;come back everi time vega&#39;, &#39;place deserv one star food&#39;, &#39;disgrac&#39;, &#39;def come back bowl next time&#39;, &#39;want healthi authent ethic food tri place&#39;, &#39;continu come ladi night andddd date night highli recommend place anyon area&#39;, &#39;sever time past experi alway great&#39;, &#39;walk away stuf happi first vega buffet experi&#39;, &#39;servic excel price pretti reason consid vega locat insid crystal shop mall aria&#39;, &#39;summar food incred nay transcend noth bring joy quit like memori pneumat condiment dispens&#39;, &#39;probabl one peopl ever go ian not like&#39;, &#39;kid pizza alway hit lot great side dish option kiddo&#39;, &#39;servic perfect famili atmospher nice see&#39;, &#39;cook perfect servic impecc&#39;, &#39;one simpli disappoint&#39;, &#39;overal disappoint qualiti food bouchon&#39;, &#39;account know get screw&#39;, &#39;great place eat remind littl mom pop shop san francisco bay area&#39;, &#39;today first tast buldogi gourmet hot dog tell ever thought possibl&#39;, &#39;left frustrat&#39;, &#39;definit soon&#39;, &#39;food realli good got full petti fast&#39;, &#39;servic fantast&#39;, &#39;total wast time&#39;, &#39;know kind best ice tea&#39;, &#39;come hungri leav happi stuf&#39;, &#39;servic give star&#39;, &#39;assur disappoint&#39;, &#39;take littl bad servic food suck&#39;, &#39;gave tri eat crust teeth still sore&#39;, &#39;complet gross&#39;, &#39;realli enjoy eat&#39;, &#39;first time go think quickli becom regular&#39;, &#39;server nice even though look littl overwhelm need stay profession friendli end&#39;, &#39;dinner companion told everyth fresh nice textur tast&#39;, &#39;ground right next tabl larg smear step track everywher pile green bird poop&#39;, &#39;furthermor even find hour oper websit&#39;, &#39;tri like place time think done&#39;, &#39;mistak&#39;, &#39;complaint&#39;, &#39;serious good pizza expert connisseur topic&#39;, &#39;waiter jerk&#39;, &#39;strike want rush&#39;, &#39;nicest restaur owner ever come across&#39;, &#39;never come&#39;, &#39;love biscuit&#39;, &#39;servic quick friendli&#39;, &#39;order appet took minut pizza anoth minut&#39;, &#39;absolutley fantast&#39;, &#39;huge awkward lb piec cow th gristl fat&#39;, &#39;definit come back&#39;, &#39;like steiner dark feel like bar&#39;, &#39;wow spici delici&#39;, &#39;not familiar check&#39;, &#39;take busi dinner dollar elsewher&#39;, &#39;love go back&#39;, &#39;anyway fs restaur wonder breakfast lunch&#39;, &#39;noth special&#39;, &#39;day week differ deal delici&#39;, &#39;not mention combin pear almond bacon big winner&#39;, &#39;not back&#39;, &#39;sauc tasteless&#39;, &#39;food delici spici enough sure ask spicier prefer way&#39;, &#39;ribey steak cook perfectli great mesquit flavor&#39;, &#39;think go back anytim soon&#39;, &#39;food gooodd&#39;, &#39;far sushi connoisseur definit tell differ good food bad food certainli bad food&#39;, &#39;insult&#39;, &#39;last time lunch bad&#39;, &#39;chicken wing contain driest chicken meat ever eaten&#39;, &#39;food good enjoy everi mouth enjoy relax venu coupl small famili group etc&#39;, &#39;nargil think great&#39;, &#39;best tater tot southwest&#39;, &#39;love place&#39;, &#39;definit not worth paid&#39;, &#39;vanilla ice cream creami smooth profiterol choux pastri fresh enough&#39;, &#39;im az time new spot&#39;, &#39;manag worst&#39;, &#39;insid realli quit nice clean&#39;, &#39;food outstand price reason&#39;, &#39;think run back carli anytim soon food&#39;, &#39;due fact took minut acknowledg anoth minut get food kept forget thing&#39;, &#39;love margarita&#39;, &#39;first vega buffet not disappoint&#39;, &#39;good though&#39;, &#39;one note ventil could use upgrad&#39;, &#39;great pork sandwich&#39;, &#39;wast time&#39;, &#39;total letdown would much rather go camelback flower shop cartel coffe&#39;, &#39;third chees friend burger cold&#39;, &#39;enjoy pizza brunch&#39;, &#39;steak well trim also perfectli cook&#39;, &#39;group claim would handl us beauti&#39;, &#39;love&#39;, &#39;ask bill leav without eat bring either&#39;, &#39;place jewel la vega exactli hope find nearli ten year live&#39;, &#39;seafood limit boil shrimp crab leg crab leg definit not tast fresh&#39;, &#39;select food not best&#39;, &#39;delici absolut back&#39;, &#39;small famili restaur fine dine establish&#39;, &#39;toro tartar cavier extraordinari like thinli slice wagyu white truffl&#39;, &#39;dont think back long time&#39;, &#39;attach ga station rare good sign&#39;, &#39;awesom&#39;, &#39;back mani time soon&#39;, &#39;menu much good stuff could not decid&#39;, &#39;wors humili worker right front bunch horribl name call&#39;, &#39;conclus fill meal&#39;, &#39;daili special alway hit group&#39;, &#39;tragedi struck&#39;, &#39;pancak also realli good pretti larg&#39;, &#39;first crawfish experi delici&#39;, &#39;monster chicken fri steak egg time favorit&#39;, &#39;waitress sweet funni&#39;, &#39;also tast mom multi grain pumpkin pancak pecan butter amaz fluffi delici&#39;, &#39;rather eat airlin food serious&#39;, &#39;cant say enough good thing place&#39;, &#39;ambianc incred&#39;, &#39;waitress manag friendli&#39;, &#39;would not recommend place&#39;, &#39;overal impress noca&#39;, &#39;gyro basic lettuc&#39;, &#39;terribl servic&#39;, &#39;thoroughli disappoint&#39;, &#39;much pasta love homemad hand made pasta thin pizza&#39;, &#39;give tri happi&#39;, &#39;far best cheesecurd ever&#39;, &#39;reason price also&#39;, &#39;everyth perfect night&#39;, &#39;food good typic bar food&#39;, &#39;drive get&#39;, &#39;first glanc love bakeri cafe nice ambianc clean friendli staff&#39;, &#39;anyway not think go back&#39;, &#39;point finger item menu order disappoint&#39;, &#39;oh thing beauti restaur&#39;, &#39;gone go&#39;, &#39;greasi unhealthi meal&#39;, &#39;first time might last&#39;, &#39;burger amaz&#39;, &#39;similarli deliveri man not say word apolog food minut late&#39;, &#39;way expens&#39;, &#39;sure order dessert even need pack go tiramisu cannoli die&#39;, &#39;first time wait next&#39;, &#39;bartend also nice&#39;, &#39;everyth good tasti&#39;, &#39;place two thumb way&#39;, &#39;best place vega breakfast check sat sun&#39;, &#39;love authent mexican food want whole bunch interest yet delici meat choos need tri place&#39;, &#39;terribl manag&#39;, &#39;excel new restaur experienc frenchman&#39;, &#39;zero star would give zero star&#39;, &#39;great steak great side great wine amaz dessert&#39;, &#39;worst martini ever&#39;, &#39;steak shrimp opinion best entre gc&#39;, &#39;opportun today sampl amaz pizza&#39;, &#39;wait thirti minut seat although vacant tabl folk wait&#39;, &#39;yellowtail carpaccio melt mouth fresh&#39;, &#39;tri go back even empti&#39;, &#39;go eat potato found stranger hair&#39;, &#39;spici enough perfect actual&#39;, &#39;last night second time dine happi decid go back&#39;, &#39;not even hello right&#39;, &#39;dessert bit strang&#39;, &#39;boyfriend came first time recent trip vega could not pleas qualiti food servic&#39;, &#39;realli recommend place go wrong donut place&#39;, &#39;nice ambianc&#39;, &#39;would recommend save room&#39;, &#39;guess mayb went night disgrac&#39;, &#39;howev recent experi particular locat not good&#39;, &#39;know not like restaur someth&#39;, &#39;avoid establish&#39;, &#39;think restaur suffer not tri hard enough&#39;, &#39;tapa dish delici&#39;, &#39;heart place&#39;, &#39;salad bland vinegrett babi green heart palm&#39;, &#39;two felt disgust&#39;, &#39;good time&#39;, &#39;believ place great stop huge belli hanker sushi&#39;, &#39;gener portion great tast&#39;, &#39;never go back place never ever recommend place anyon&#39;, &#39;server went back forth sever time not even much help&#39;, &#39;food delici&#39;, &#39;hour serious&#39;, &#39;consid theft&#39;, &#39;eew locat need complet overhaul&#39;, &#39;recent wit poor qualiti manag toward guest well&#39;, &#39;wait wait wait&#39;, &#39;also came back check us regularli excel servic&#39;, &#39;server super nice check us mani time&#39;, &#39;pizza tast old super chewi not good way&#39;, &#39;swung give tri deepli disappoint&#39;, &#39;servic good compani better&#39;, &#39;staff also friendli effici&#39;, &#39;servic fan quick serv nice folk&#39;, &#39;boy sucker dri&#39;, &#39;rate&#39;, &#39;look authent thai food go els&#39;, &#39;steak recommend&#39;, &#39;pull car wait anoth minut acknowledg&#39;, &#39;great food great servic clean friendli set&#39;, &#39;assur back&#39;, &#39;hate thing much cheap qualiti black oliv&#39;, &#39;breakfast perpar great beauti present giant slice toast lightli dust powder sugar&#39;, &#39;kid play area nasti&#39;, &#39;great place fo take eat&#39;, &#39;waitress friendli happi accomod vegan veggi option&#39;, &#39;omg felt like never eaten thai food dish&#39;, &#39;extrem crumbi pretti tasteless&#39;, &#39;pale color instead nice char flavor&#39;, &#39;crouton also tast homemad extra plu&#39;, &#39;got home see driest damn wing ever&#39;, &#39;regular stop trip phoenix&#39;, &#39;realli enjoy crema caf expand even told friend best breakfast&#39;, &#39;not good money&#39;, &#39;miss wish one philadelphia&#39;, &#39;got sit fairli fast end wait minut place order anoth minut food arriv&#39;, &#39;also best chees crisp town&#39;, &#39;good valu great food great servic&#39;, &#39;ask satisfi meal&#39;, &#39;food good&#39;, &#39;awesom&#39;, &#39;want leav&#39;, &#39;made drive way north scottsdal not one bit disappoint&#39;, &#39;not eat&#39;, &#39;owner realli realli need quit soooooo cheap let wrap freak sandwich two paper not one&#39;, &#39;check place coupl year ago not impress&#39;, &#39;chicken got definit reheat ok wedg cold soggi&#39;, &#39;sorri not get food anytim soon&#39;, &#39;absolut must visit&#39;, &#39;cow tongu cheek taco amaz&#39;, &#39;friend not like bloodi mari&#39;, &#39;despit hard rate busi actual rare give star&#39;, &#39;realli want make experi good one&#39;, &#39;not return&#39;, &#39;chicken pho tast bland&#39;, &#39;disappoint&#39;, &#39;grill chicken tender yellow saffron season&#39;, &#39;drive thru mean not want wait around half hour food somehow end go make us wait wait&#39;, &#39;pretti awesom place&#39;, &#39;ambienc perfect&#39;, &#39;best luck rude non custom servic focus new manag&#39;, &#39;grandmoth make roast chicken better one&#39;, &#39;ask multipl time wine list time ignor went hostess got one&#39;, &#39;staff alway super friendli help especi cool bring two small boy babi&#39;, &#39;four star food guy blue shirt great vibe still let us eat&#39;, &#39;roast beef sandwich tast realli good&#39;, &#39;even drastic sick&#39;, &#39;high qualiti chicken chicken caesar salad&#39;, &#39;order burger rare came done&#39;, &#39;promptli greet seat&#39;, &#39;tri go lunch madhous&#39;, &#39;proven dead wrong sushi bar not qualiti great servic fast food impecc&#39;, &#39;wait hour seat not greatest mood&#39;, &#39;good joint&#39;, &#39;macaron insan good&#39;, &#39;not eat&#39;, &#39;waiter attent friendli inform&#39;, &#39;mayb cold would somewhat edibl&#39;, &#39;place lot promis fail deliv&#39;, &#39;bad experi&#39;, &#39;mistak&#39;, &#39;food averag best&#39;, &#39;great food&#39;, &#39;go back anytim soon&#39;, &#39;disappoint order big bay plater&#39;, &#39;great place relax awesom burger beer&#39;, &#39;perfect sit famili meal get togeth friend&#39;, &#39;not much flavor poorli construct&#39;, &#39;patio seat comfort&#39;, &#39;fri rice dri well&#39;, &#39;hand favorit italian restaur&#39;, &#39;scream legit book somethat also pretti rare vega&#39;, &#39;not fun experi&#39;, &#39;atmospher great love duo violinist play song request&#39;, &#39;person love hummu pita baklava falafel baba ganoush amaz eggplant&#39;, &#39;conveni sinc stay mgm&#39;, &#39;owner super friendli staff courteou&#39;, &#39;great&#39;, &#39;eclect select&#39;, &#39;sweet potato tot good onion ring perfect close&#39;, &#39;staff attent&#39;, &#39;chef gener time even came around twice take pictur&#39;, &#39;owner use work nobu place realli similar half price&#39;, &#39;googl mediocr imagin smashburg pop&#39;, &#39;dont go&#39;, &#39;promis disappoint&#39;, &#39;sushi lover avoid place mean&#39;, &#39;great doubl cheeseburg&#39;, &#39;awesom servic food&#39;, &#39;fantast neighborhood gem&#39;, &#39;wait go back&#39;, &#39;plantain worst ever tast&#39;, &#39;great place highli recommend&#39;, &#39;servic slow not attent&#39;, &#39;gave star give star&#39;, &#39;staff spend time talk&#39;, &#39;dessert panna cotta amaz&#39;, &#39;good food great atmospher&#39;, &#39;damn good steak&#39;, &#39;total brunch fail&#39;, &#39;price reason flavor spot sauc home made slaw not drench mayo&#39;, &#39;decor nice piano music soundtrack pleasant&#39;, &#39;steak amaz rge fillet relleno best seafood plate ever&#39;, &#39;good food good servic&#39;, &#39;absolut amaz&#39;, &#39;probabl back honest&#39;, &#39;definit back&#39;, &#39;sergeant pepper beef sandwich auju sauc excel sandwich well&#39;, &#39;hawaiian breez mango magic pineappl delight smoothi tri far good&#39;, &#39;went lunch servic slow&#39;, &#39;much say place walk expect amaz quickli disappoint&#39;, &#39;mortifi&#39;, &#39;needless say never back&#39;, &#39;anyway food definit not fill price pay expect&#39;, &#39;chip came drip greas mostli not edibl&#39;, &#39;realli impress strip steak&#39;, &#39;go sinc everi meal awesom&#39;, &#39;server nice attent serv staff&#39;, &#39;cashier friendli even brought food&#39;, &#39;work hospit industri paradis valley refrain recommend cibo longer&#39;, &#39;atmospher fun&#39;, &#39;would not recommend other&#39;, &#39;servic quick even go order like like&#39;, &#39;mean realli get famou fish chip terribl&#39;, &#39;said mouth belli still quit pleas&#39;, &#39;not thing&#39;, &#39;thumb&#39;, &#39;read pleas go&#39;, &#39;love grill pizza remind legit italian pizza&#39;, &#39;pro larg seat area nice bar area great simpl drink menu best brick oven pizza homemad dough&#39;, &#39;realli nice atmospher&#39;, &#39;tonight elk filet special suck&#39;, &#39;one bite hook&#39;, &#39;order old classic new dish go time sore disappoint everyth&#39;, &#39;cute quaint simpl honest&#39;, &#39;chicken delici season perfect fri outsid moist chicken insid&#39;, &#39;food great alway compliment chef&#39;, &#39;special thank dylan recommend order yummi tummi&#39;, &#39;awesom select beer&#39;, &#39;great food awesom servic&#39;, &#39;one nice thing ad gratuiti bill sinc parti larger expect tip&#39;, &#39;fli appl juic fli&#39;, &#39;han nan chicken also tasti&#39;, &#39;servic thought good&#39;, &#39;food bare lukewarm must sit wait server bring us&#39;, &#39;ryan bar definit one edinburgh establish revisit&#39;, &#39;nicest chines restaur&#39;, &#39;overal like food servic&#39;, &#39;also serv indian naan bread hummu spici pine nut sauc world&#39;, &#39;probabl never come back recommend&#39;, &#39;friend pasta also bad bare touch&#39;, &#39;tri airport experi tasti food speedi friendli servic&#39;, &#39;love decor chines calligraphi wall paper&#39;, &#39;never anyth complain&#39;, &#39;restaur clean famili restaur feel&#39;, &#39;way fri&#39;, &#39;not sure long stood long enough begin feel awkwardli place&#39;, &#39;open sandwich impress not good way&#39;, &#39;not back&#39;, &#39;warm feel servic felt like guest special treat&#39;, &#39;extens menu provid lot option breakfast&#39;, &#39;alway order vegetarian menu dinner wide array option choos&#39;, &#39;watch price inflat portion get smaller manag attitud grow rapidli&#39;, &#39;wonder lil tapa ambienc made feel warm fuzzi insid&#39;, &#39;got enjoy seafood salad fabul vinegrett&#39;, &#39;wonton thin not thick chewi almost melt mouth&#39;, &#39;level spici perfect spice whelm soup&#39;, &#39;sat right time server get go fantast&#39;, &#39;main thing enjoy crowd older crowd around mid&#39;, &#39;side town definit spot hit&#39;, &#39;wait minut get drink longer get arepa&#39;, &#39;great place eat&#39;, &#39;jalapeno bacon soooo good&#39;, &#39;servic poor that nice&#39;, &#39;food good servic good price good&#39;, &#39;place not clean food oh stale&#39;, &#39;chicken dish ok beef like shoe leather&#39;, &#39;servic beyond bad&#39;, &#39;happi&#39;, &#39;tast like dirt&#39;, &#39;one place phoenix would defin go back&#39;, &#39;block amaz&#39;, &#39;close hous low key non fanci afford price good food&#39;, &#39;hot sour egg flower soup absolut star&#39;, &#39;sashimi poor qualiti soggi tasteless&#39;, &#39;great time famili dinner sunday night&#39;, &#39;food not tasti not say real tradit hunan style&#39;, &#39;bother slow servic&#39;, &#39;flair bartend absolut amaz&#39;, &#39;frozen margarita way sugari tast&#39;, &#39;good order twice&#39;, &#39;nutshel restaraunt smell like combin dirti fish market sewer&#39;, &#39;girlfriend veal bad&#39;, &#39;unfortun not good&#39;, &#39;pretti satifi experi&#39;, &#39;join club get awesom offer via email&#39;, &#39;perfect someon like beer ice cold case even colder&#39;, &#39;bland flavorless good way describ bare tepid meat&#39;, &#39;chain fan beat place easili&#39;, &#39;nacho must&#39;, &#39;not come back&#39;, &#39;mani word say place everyth pretti well&#39;, &#39;staff super nice quick even crazi crowd downtown juri lawyer court staff&#39;, &#39;great atmospher friendli fast servic&#39;, &#39;receiv pita huge lot meat thumb&#39;, &#39;food arriv meh&#39;, &#39;pay hot dog fri look like came kid meal wienerschnitzel not idea good meal&#39;, &#39;classic main lobster roll fantast&#39;, &#39;brother law work mall ate day guess sick night&#39;, &#39;good go review place twice herea tribut place tribut event held last night&#39;, &#39;chip salsa realli good salsa fresh&#39;, &#39;place great&#39;, &#39;mediocr food&#39;, &#39;get insid impress place&#39;, &#39;super pissd&#39;, &#39;servic super friendli&#39;, &#39;sad littl veget overcook&#39;, &#39;place nice surpris&#39;, &#39;golden crispi delici&#39;, &#39;high hope place sinc burger cook charcoal grill unfortun tast fell flat way flat&#39;, &#39;could eat bruschetta day devin&#39;, &#39;not singl employe came see ok even need water refil final serv us food&#39;, &#39;lastli mozzarella stick best thing order&#39;, &#39;first time ever came amaz experi still tell peopl awesom duck&#39;, &#39;server neglig need made us feel unwelcom would not suggest place&#39;, &#39;servic terribl though&#39;, &#39;place overpr not consist boba realli overpr&#39;, &#39;pack&#39;, &#39;love place&#39;, &#39;say dessert yummi&#39;, &#39;food terribl&#39;, &#39;season fruit fresh white peach pure&#39;, &#39;kept get wors wors offici done&#39;, &#39;place honestli blown&#39;, &#39;definit would not eat&#39;, &#39;not wast money&#39;, &#39;love put food nice plastic contain oppos cram littl paper takeout box&#39;, &#39;cr pe delic thin moist&#39;, &#39;aw servic&#39;, &#39;ever go&#39;, &#39;food qualiti horribl&#39;, &#39;price think place would much rather gone&#39;, &#39;servic fair best&#39;, &#39;love sushi found kabuki price hip servic&#39;, &#39;favor stay away dish&#39;, &#39;poor servic&#39;, &#39;one tabl thought food averag worth wait&#39;, &#39;best servic food ever maria server good friendli made day&#39;, &#39;excel&#39;, &#39;paid bill not tip felt server terribl job&#39;, &#39;lunch great experi&#39;, &#39;never bland food surpris consid articl read focus much spice flavor&#39;, &#39;food way overpr portion fuck small&#39;, &#39;recent tri caballero back everi week sinc&#39;, &#39;buck head realli expect better food&#39;, &#39;food came good pace&#39;, &#39;ate twice last visit especi enjoy salmon salad&#39;, &#39;back&#39;, &#39;could not believ dirti oyster&#39;, &#39;place deserv star&#39;, &#39;would not recommend place&#39;, &#39;fact go round star awesom&#39;, &#39;disbelief dish qualifi worst version food ever tast&#39;, &#39;bad day not low toler rude custom servic peopl job nice polit wash dish otherwis&#39;, &#39;potato great biscuit&#39;, &#39;probabl would not go&#39;, &#39;flavor perfect amount heat&#39;, &#39;price reason servic great&#39;, &#39;wife hate meal coconut shrimp friend realli not enjoy meal either&#39;, &#39;fella got huevo ranchero look appeal&#39;, &#39;went happi hour great list wine&#39;, &#39;may say buffet pricey think get pay place get quit lot&#39;, &#39;probabl come back&#39;, &#39;worst food servic&#39;, &#39;place pretti good nice littl vibe restaur&#39;, &#39;talk great custom servic cours back&#39;, &#39;hot dish not hot cold dish close room temp watch staff prepar food bare hand glove everyth deep fri oil&#39;, &#39;love fri bean&#39;, &#39;alway pleasur deal&#39;, &#39;plethora salad sandwich everyth tri get seal approv&#39;, &#39;place awesom want someth light healthi summer&#39;, &#39;sushi strip place go&#39;, &#39;servic great even manag came help tabl&#39;, &#39;feel dine room colleg cook cours high class dine servic slow best&#39;, &#39;start review two star edit give one&#39;, &#39;worst sushi ever eat besid costco&#39;, &#39;excel restaur highlight great servic uniqu menu beauti set&#39;, &#39;boyfriend sat bar complet delight experi&#39;, &#39;weird vibe owner&#39;, &#39;hardli meat&#39;, &#39;better bagel groceri store&#39;, &#39;go place gyro&#39;, &#39;love owner chef one authent japanes cool dude&#39;, &#39;burger good pizza use amaz doughi flavorless&#39;, &#39;found six inch long piec wire salsa&#39;, &#39;servic terribl food mediocr&#39;, &#39;defin enjoy&#39;, &#39;order albondiga soup warm tast like tomato soup frozen meatbal&#39;, &#39;three differ occas ask well done medium well three time got bloodiest piec meat plate&#39;, &#39;two bite refus eat anymor&#39;, &#39;servic extrem slow&#39;, &#39;minut wait got tabl&#39;, &#39;serious killer hot chai latt&#39;, &#39;allergi warn menu waitress absolut clue meal not contain peanut&#39;, &#39;boyfriend tri mediterranean chicken salad fell love&#39;, &#39;rotat beer tap also highlight place&#39;, &#39;price bit concern mellow mushroom&#39;, &#39;worst thai ever&#39;, &#39;stay vega must get breakfast least&#39;, &#39;want first say server great perfect servic&#39;, &#39;pizza select good&#39;, &#39;strawberri tea good&#39;, &#39;highli unprofession rude loyal patron&#39;, &#39;overal great experi&#39;, &#39;spend money elsewher&#39;, &#39;regular toast bread equal satisfi occasion pat butter mmmm&#39;, &#39;buffet bellagio far anticip&#39;, &#39;drink weak peopl&#39;, &#39;order not correct&#39;, &#39;also feel like chip bought not made hous&#39;, &#39;disappoint dinner went elsewher dessert&#39;, &#39;chip sal amaz&#39;, &#39;return&#39;, &#39;new fav vega buffet spot&#39;, &#39;serious cannot believ owner mani unexperienc employe run around like chicken head cut&#39;, &#39;sad&#39;, &#39;felt insult disrespect could talk judg anoth human like&#39;, &#39;call steakhous properli cook steak understand&#39;, &#39;not impress concept food&#39;, &#39;thing crazi guacamol like pur ed&#39;, &#39;realli noth postino hope experi better&#39;, &#39;got food poison buffet&#39;, &#39;brought fresh batch fri think yay someth warm&#39;, &#39;hilari yummi christma eve dinner rememb biggest fail entir trip us&#39;, &#39;needless say go back anytim soon&#39;, &#39;place disgust&#39;, &#39;everi time eat see care teamwork profession degre&#39;, &#39;ri style calamari joke&#39;, &#39;howev much garlic fondu bare edibl&#39;, &#39;could bare stomach meal complain busi lunch&#39;, &#39;bad lost heart finish&#39;, &#39;also took forev bring us check ask&#39;, &#39;one make scene restaur get definit lost love one&#39;, &#39;disappoint experi&#39;, &#39;food par denni say not good&#39;, &#39;want wait mediocr food downright terribl servic place&#39;, &#39;waaaaaayyyyyyyyyi rate say&#39;, &#39;go back&#39;, &#39;place fairli clean food simpli worth&#39;, &#39;place lack style&#39;, &#39;sangria half glass wine full ridicul&#39;, &#39;bother come&#39;, &#39;meat pretti dri slice brisket pull pork&#39;, &#39;build seem pretti neat bathroom pretti trippi eat&#39;, &#39;equal aw&#39;, &#39;probabl not hurri go back&#39;, &#39;slow seat even reserv&#39;, &#39;not good stretch imagin&#39;, &#39;cashew cream sauc bland veget undercook&#39;, &#39;chipolt ranch dip saus tasteless seem thin water heat&#39;, &#39;bit sweet not realli spici enough lack flavor&#39;, &#39;disappoint&#39;, &#39;place horribl way overpr&#39;, &#39;mayb vegetarian fare twice thought averag best&#39;, &#39;busi know&#39;, &#39;tabl outsid also dirti lot time worker not alway friendli help menu&#39;, &#39;ambianc not feel like buffet set douchey indoor garden tea biscuit&#39;, &#39;con spotti servic&#39;, &#39;fri not hot neither burger&#39;, &#39;came back cold&#39;, &#39;food came disappoint ensu&#39;, &#39;real disappoint waiter&#39;, &#39;husband said rude not even apolog bad food anyth&#39;, &#39;reason eat would fill night bing drink get carb stomach&#39;, &#39;insult profound deuchebaggeri go outsid smoke break serv solidifi&#39;, &#39;someon order two taco think may part custom servic ask combo ala cart&#39;, &#39;quit disappoint although blame need place door&#39;, &#39;rave review wait eat disappoint&#39;, &#39;del taco pretti nasti avoid possibl&#39;, &#39;not hard make decent hamburg&#39;, &#39;like&#39;, &#39;hell go back&#39;, &#39;gotten much better servic pizza place next door servic receiv restaur&#39;, &#39;know big deal place back ya&#39;, &#39;immedi said want talk manag not want talk guy shot firebal behind bar&#39;, &#39;ambianc much better&#39;, &#39;unfortun set us disapppoint entre&#39;, &#39;food good&#39;, &#39;server suck wait correct server heimer suck&#39;, &#39;happen next pretti put&#39;, &#39;bad caus know famili own realli want like place&#39;, &#39;overpr get&#39;, &#39;vomit bathroom mid lunch&#39;, &#39;kept look time soon becom minut yet still food&#39;, &#39;place eat circumst would ever return top list&#39;, &#39;start tuna sashimi brownish color obvious fresh&#39;, &#39;food averag&#39;, &#39;sure beat nacho movi would expect littl bit come restaur&#39;, &#39;ha long bay bit flop&#39;, &#39;problem charg sandwich bigger subway sub offer better amount veget&#39;, &#39;shrimp unwrap live mile brushfir liter ice cold&#39;, &#39;lack flavor seem undercook dri&#39;, &#39;realli impress place close&#39;, &#39;would avoid place stay mirag&#39;, &#39;refri bean came meal dri crusti food bland&#39;, &#39;spend money time place els&#39;, &#39;ladi tabl next us found live green caterpillar salad&#39;, &#39;present food aw&#39;, &#39;tell disappoint&#39;, &#39;think food flavor textur lack&#39;, &#39;appetit instantli gone&#39;, &#39;overal not impress would not go back&#39;, &#39;whole experi underwhelm think go ninja sushi next time&#39;, &#39;wast enough life pour salt wound draw time took bring check&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;creating-the-bag-of-words-model&#34;&gt;Creating the Bag of Words model&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 1500)
X = cv.fit_transform(corpus).toarray()
y = dataset.iloc[:, -1].values
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;splitting-the-dataset-into-the-training-set-and-test-set&#34;&gt;Splitting the dataset into the Training set and Test set&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;training-the-naive-bayes-model-on-the-training-set&#34;&gt;Training the Naive Bayes model on the Training set&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;GaussianNB(priors=None, var_smoothing=1e-09)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;predicting-the-test-set-results&#34;&gt;Predicting the Test set results&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;y_pred = classifier.predict(X_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[[1 0]
 [1 0]
 [1 1]
 [1 1]
 [1 1]
 [0 0]
 [1 0]
 [0 0]
 [1 0]
 [1 1]
 [1 1]
 [1 0]
 [1 1]
 [0 0]
 [0 0]
 [0 0]
 [1 0]
 [1 0]
 [0 0]
 [0 0]
 [1 1]
 [1 1]
 [1 1]
 [1 1]
 [1 0]
 [0 0]
 [1 1]
 [1 1]
 [0 0]
 [1 1]
 [1 0]
 [0 0]
 [1 0]
 [1 0]
 [1 1]
 [0 0]
 [1 1]
 [1 1]
 [1 1]
 [1 0]
 [1 1]
 [1 1]
 [1 1]
 [1 1]
 [0 0]
 [1 0]]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;making-the-confusion-matrix&#34;&gt;Making the Confusion Matrix&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[[55 42]
 [12 91]]





0.73
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Display Jupyter Notebooks with Academic</title>
      <link>https://richakbee.github.io/post/jupyter/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://richakbee.github.io/post/jupyter/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.core.display import Image
Image(&#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_1_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(&amp;quot;Welcome to Academic!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Welcome to Academic!
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;install-python-and-jupyterlab&#34;&gt;Install Python and JupyterLab&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.anaconda.com/distribution/#download-section&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Install Anaconda&lt;/a&gt; which includes Python 3 and JupyterLab.&lt;/p&gt;
&lt;p&gt;Alternatively, install JupyterLab with &lt;code&gt;pip3 install jupyterlab&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;create-or-upload-a-jupyter-notebook&#34;&gt;Create or upload a Jupyter notebook&lt;/h2&gt;
&lt;p&gt;Run the following commands in your Terminal, substituting &lt;code&gt;&amp;lt;MY-WEBSITE-FOLDER&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;SHORT-POST-TITLE&amp;gt;&lt;/code&gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/
cd &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/
jupyter lab index.ipynb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;jupyter&lt;/code&gt; command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.&lt;/p&gt;
&lt;h2 id=&#34;edit-your-post-metadata&#34;&gt;Edit your post metadata&lt;/h2&gt;
&lt;p&gt;The first cell of your Jupter notebook will contain your post metadata (&lt;a href=&#34;https://sourcethemes.com/academic/docs/front-matter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;front matter&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In Jupter, choose &lt;em&gt;Markdown&lt;/em&gt; as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
title: My post&#39;s title
date: 2019-09-01

# Put any other Academic metadata here...
---
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Edit the metadata of your post, using the &lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; as a guide to the available options.&lt;/p&gt;
&lt;p&gt;To set a &lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#featured-image&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;featured image&lt;/a&gt;, place an image named &lt;code&gt;featured&lt;/code&gt; into your post&amp;rsquo;s folder.&lt;/p&gt;
&lt;p&gt;For other tips, such as using math, see the guide on &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;writing content with Academic&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;convert-notebook-to-markdown&#34;&gt;Convert notebook to Markdown&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p&gt;This post was created with Jupyter. The orginal files can be found at &lt;a href=&#34;https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter&#34;&gt;https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
